#include <cscore.h>
#include <ntcore.h>
#include <networktables/NetworkTableInstance.h>
#include <opencv2/core/core.hpp>
#include <opencv2/videoio/videoio.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <iostream>
#include <stdio.h>  /* printf() */
#include <string.h> /* memcpy() */
#include <inttypes.h>

#include <chrono>
#include <thread>

#include <VMXPi.h>
#include <VisionPipeline.h>
#include "pipeline/GripPipeline.h" /* This file is auto-generated by Grip */
using namespace cs;
using namespace nt;
using namespace cv;
using namespace frc;

#ifndef NULL
#define NULL 0
#endif

int main() {
	/* Instantiate pipeline exported from GRIP.  If not using grip, set pipeline = NULL; */
	VisionPipeline *p_pipeline = new GripPipeline();
	
	const char* p_outputVideoFilePath = "/media/pi/data/output.avi"; /* Set to NULL if video writing not desired */
	
	/* Open communication to VMX-pi, to acquire IMU data */
	VMXPi vmx(false, 50);
	if (!vmx.IsOpen()) {
		printf("Error:  Unable to open VMX Client.\n");
		printf("\n");
		printf("        - Is pigpio (or the system resources it requires) in use by another process?\n");
		printf("        - Does this application have root privileges?\n");
		exit(1);
	}

	/* Connect NetworkTables */
	/* Note:  actual IP address should be robot IP address */
	NetworkTableInstance inst = NetworkTableInstance::GetDefault();
	inst.StartClient("192.168.0.113");

	/* Open connection to USB Camera (video device 0 [/dev/video0]) */
	UsbCamera camera("usbcam", 0);

	/* Configure Camera */
	/* Note:  Higher resolution & framerate is possible, depending upon processing cpu usage */
	int width = 320;
	int height = 240;
	int frames_per_sec = 15;
	camera.SetVideoMode(VideoMode::PixelFormat::kMJPEG, width, height, frames_per_sec);
		
	/* Start raw Video Streaming Server */
	MjpegServer rawVideoServer("raw_video_server", 8081);
	rawVideoServer.SetSource(camera);
	CvSink cvsink("cvsink");
	cvsink.SetSource(camera);

	/* Start processed Video server */
	CvSource cvsource("cvsource",
			VideoMode::PixelFormat::kMJPEG, width, height, frames_per_sec);
	MjpegServer processedVideoServer("processed_video_server", 8082);
	processedVideoServer.SetSource(cvsource);

	/* Create Video Writer, if enabled */
	Size frameSize(width, height);
	VideoWriter *p_videoWriter = NULL;
	if (p_outputVideoFilePath != NULL) {
		p_videoWriter = new VideoWriter(p_outputVideoFilePath,
			VideoWriter::fourcc('F', 'M', 'P', '4'), (double)frames_per_sec, frameSize, true);
	}

	/* Pre-allocate a video frame */
	Mat frame;

	int count = 0;
	while (count < 100) {
		/* Acquire new video frame */
		std::string videoTimestampString;
		uint64_t video_timestamp = cvsink.GrabFrame(frame);
		if (video_timestamp == 0) {
			std::string error_string = cvsink.GetError();
			printf("Error Grabbing Video Frame:  %s\n", error_string.c_str());
			std::this_thread::sleep_for(std::chrono::milliseconds((1000/frames_per_sec)/2));
			continue;
		} else {
			videoTimestampString = std::to_string(video_timestamp);
			printf("Video Timestamp:  %llu\n", video_timestamp);
		}			

		/* Overlay timestamps & orientation data onto video */
	        putText (
	           frame,                          // Video frame
	           videoTimestampString,       	   // Text to be added
	           Point(30, 30),                  // point
	           FONT_HERSHEY_SIMPLEX ,          // front face
	           0.5,                            // front scale
	           Scalar(255, 255, 255),          // Scalar object for color (RGB)
	           2                               // Thickness
		);
		std::string imuTimestampString = std::to_string(vmx.getAHRS().GetLastSensorTimestamp());
	        putText (
	           frame,                          // Video frame
	           imuTimestampString,        	   // Text to be added
	           Point(30, 50),                  // point
	           FONT_HERSHEY_SIMPLEX,           // front face
	           0.5,                            // front scale
	           Scalar(255, 255, 255),          // Scalar object for color (RGB)
	           2                               // Thickness
		);
		std::string yawString = std::to_string(vmx.getAHRS().GetYaw());
	        putText (
	           frame,                          // Video frame
	           yawString,          	   	   // Text to be added
	           Point(30, 70),                  // point
	           FONT_HERSHEY_SIMPLEX ,          // front face
	           0.5,                            // front scale
	           Scalar(255, 255, 255),          // Scalar object for color (RGB)
	           2                               // Thickness
		);
		std::string pitchString = std::to_string(vmx.getAHRS().GetPitch());
	        putText (
	           frame,                          // Video frame
	           pitchString,          	   // Text to be added
	           Point(30, 90),                  // point
	           FONT_HERSHEY_SIMPLEX ,          // front face
	           0.5,                            // front scale
	           Scalar(255, 255, 255),          // Scalar object for color (RGB)
	           2                               // Thickness
		);
		std::string rollString = std::to_string(vmx.getAHRS().GetRoll());
	        putText (
	           frame,                          // Video frame
	           rollString,          	   // Text to be added
	           Point(30, 110),                 // point
	           FONT_HERSHEY_SIMPLEX ,          // front face
	           0.5,                            // front scale
	           Scalar(255, 255, 255),          // Scalar object for color (RGB)
	           2                               // Thickness
		);

		/* Update Network Tables with timestamps & orientation data */
		inst.GetEntry("/vmx/videoOSTimestamp").SetDouble(video_timestamp);
		inst.GetEntry("/vmx/navxSensorTimestamp").SetDouble(vmx.getAHRS().GetLastSensorTimestamp());
		inst.GetEntry("/vmx/navxYaw").SetDouble(vmx.getAHRS().GetYaw());
		inst.GetEntry("/vmx/navxPitch").SetDouble(vmx.getAHRS().GetPitch());
		inst.GetEntry("/vmx/navxRoll").SetDouble(vmx.getAHRS().GetRoll());

		/* Invoke processing pipeline, if one is present */
		if (p_pipeline != NULL) {
			p_pipeline->Process(frame);
		}

		/* Write Frame to video */
		if (p_videoWriter != NULL) {
			p_videoWriter->write(frame);
		}

		count++;
	}
	if (p_videoWriter != NULL) {
		delete p_videoWriter;
	}
	if (p_pipeline != NULL) {
		delete p_pipeline;
	}
}

